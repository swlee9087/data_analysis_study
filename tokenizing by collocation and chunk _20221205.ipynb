{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d0b3fc",
   "metadata": {},
   "source": [
    "### collocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fefca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REF https://m.blog.naver.com/vangarang/221076777192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d6a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18884\n"
     ]
    }
   ],
   "source": [
    "from konlpy.corpus import kolaw\n",
    "print( len( kolaw.open('constitution.txt').read() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "124ef159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramAssocMeasures\n",
    "from nltk.collocations import TrigramAssocMeasures\n",
    "from nltk.metrics.association import QuadgramAssocMeasures\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.collocations import QuadgramCollocationFinder\n",
    "\n",
    "ngram = [(BigramAssocMeasures(),BigramCollocationFinder),\n",
    "         (TrigramAssocMeasures(),TrigramCollocationFinder),\n",
    "         (QuadgramAssocMeasures(),QuadgramCollocationFinder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6650d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "s = kolaw.open('constitution.txt').read() # 한국 법률 말뭉치\n",
    "okt = Okt()      # loading tagger\n",
    "tokens = okt.pos(s, norm=True, stem=True)  # pos tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bb7fce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'각각의 AssocMeasures들은 단어 간의 연관도 측정 알고리즘을 담고있습니다. \\n연관도 측정 방법은 연관도를 정의하는 방법에 따라 다양하게 나눠지는데요. \\nNLTK에서는 이 알고리즘들을 함수로 각각 구현해놓았습니다. \\n각각 pmi, raw_freq, student_t, chi_sq, mi_like, poisson_stirling, jaccard, likelihood_ratio (8) 입니다.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''각각의 AssocMeasures들은 단어 간의 연관도 측정 알고리즘을 담고있습니다. \n",
    "연관도 측정 방법은 연관도를 정의하는 방법에 따라 다양하게 나눠지는데요. \n",
    "NLTK에서는 이 알고리즘들을 함수로 각각 구현해놓았습니다. \n",
    "각각 pmi, raw_freq, student_t, chi_sq, mi_like, poisson_stirling, jaccard, likelihood_ratio (8) 입니다.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1edda0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "founds_from_4measure = []\n",
    "\n",
    "for measure, finder in ngram:\n",
    "    finder = finder.from_words(tokens)\n",
    "    founds = finder.nbest(measure.pmi, 10)       # pmi - 상위 10개 추출\n",
    "    founds += finder.nbest(measure.chi_sq, 10)   # chi_sq - 상위 10개 추출\n",
    "    founds += finder.nbest(measure.mi_like, 10)  # mi_like - 상위 10개 추출\n",
    "    founds += finder.nbest(measure.jaccard, 10)  # jaccard - 상위 10개 추출\n",
    "\n",
    "    founds_from_4measure += founds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d2d0cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1948년 7월 12일', 4),\n",
      " ('1988년 2월 25일', 4),\n",
      " ('2월 25일 부터', 4),\n",
      " ('7월 12일 에', 4),\n",
      " ('가부 동 수인', 4),\n",
      " ('국립 대학교 총장', 4),\n",
      " ('군 경의 유가족', 4),\n",
      " ('농수산 물의 수급', 4),\n",
      " ('선거일 현재 40', 4),\n",
      " ('우호 통상 항해', 4),\n",
      " ('1948년 7월 12일 에', 4),\n",
      " ('1988년 2월 25일 부터', 4),\n",
      " ('전몰 군 경의 유가족', 4),\n",
      " ('\\n\\n  펼치다 부칙 <', 4),\n",
      " ('29 .> 부칙 보기', 4),\n",
      " ('70일 내지 40일 전에', 4),\n",
      " ('계 도하 고 생산품', 4),\n",
      " ('빛나다 우리 대 한', 4),\n",
      " ('선거일 현재 40 세', 4),\n",
      " ('.> 부칙 보기 \\n\\n', 4),\n",
      " ('\\n\\n  펼치다', 3),\n",
      " ('\" 나', 3),\n",
      " ('12일 에', 3),\n",
      " ('1948년 7월', 3),\n",
      " ('1988년 2월', 3),\n",
      " ('25일 부터', 3),\n",
      " ('29 .>', 3),\n",
      " ('2월 25일', 3),\n",
      " ('40조 입법권', 3),\n",
      " ('58조 국채', 3)]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.utils import pprint\n",
    "from collections import Counter\n",
    "collocations = [' '.join([w for w,t in collocation]) for collocation in founds_from_4measure]\n",
    "collocations = [(w,f) for w,f in Counter(collocations).most_common() if f > 2]\n",
    "pprint(collocations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d0573",
   "metadata": {},
   "source": [
    "### chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29089d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REF https://m.blog.naver.com/vangarang/221076896346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "add4daff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Print whole tree\n",
      "(S\n",
      "  (NP 만/Noun 6/Number 세/Noun 이하/Noun)\n",
      "  의/Josa\n",
      "  (NP 초등학교/Noun 취학/Noun 전/Noun 자녀/Noun)\n",
      "  를/Josa\n",
      "  (NP 양육/Noun)\n",
      "  하기/Verb\n",
      "  (NP 위/Noun)\n",
      "  해서는/Verb)\n"
     ]
    }
   ],
   "source": [
    "import konlpy\n",
    "import nltk\n",
    "\n",
    "# POS tag a sentence\n",
    "sentence = u'만 6세 이하의 초등학교 취학 전 자녀를 양육하기 위해서는'\n",
    "words = okt.pos(sentence)\n",
    "\n",
    "# Define a chunk grammar, or chunking rules, then chunk\n",
    "grammar = \"\"\"\n",
    "NP: {<N.*>*<Suffix>?}   # Noun phrase\n",
    "\"\"\"\n",
    "parser = nltk.RegexpParser(grammar)\n",
    "chunks = parser.parse(words)\n",
    "print(\"# Print whole tree\")\n",
    "chunks.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a8ba5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [ chunk.leaves() for chunk in chunks if type(chunk) != tuple ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3659eaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('만', 'Noun'), ('6', 'Number'), ('세', 'Noun'), ('이하', 'Noun')],\n",
       " [('초등학교', 'Noun'), ('취학', 'Noun'), ('전', 'Noun'), ('자녀', 'Noun')],\n",
       " [('양육', 'Noun')],\n",
       " [('위', 'Noun')]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2437091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# chunk를 본문과 같이 만들고 빈도 수 카운팅\n",
    "result = set()\n",
    "for chunk in chunks:\n",
    "    seq = [w for w, t in chunk]\n",
    "    pattern = '[ ]?'.join(seq)\n",
    "    if len(pattern) < 2:\n",
    "        continue\n",
    "    seq_pattern = re.compile(pattern)\n",
    "    founds = re.findall(seq_pattern, sentence)\n",
    "    len_founds = len(founds)\n",
    "    if not len_founds:\n",
    "        continue\n",
    "    ele = (founds[0], len_founds)\n",
    "    if len(set(founds)) > 1:\n",
    "        ele = (tuple(set(founds)), len_founds)\n",
    "    result.add(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0162e23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('만 6세 이하', 1), ('양육', 1), ('초등학교 취학 전 자녀', 1)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ba39404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12c37c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('구성', 9),\n",
      " ('정치', 9),\n",
      " ('자치', 9),\n",
      " ('법률안', 9),\n",
      " ('사회', 9),\n",
      " ('행위', 9),\n",
      " ('체포', 9),\n",
      " ('효력', 9),\n",
      " ('투표', 9),\n",
      " ('대하여', 9),\n",
      " ('대하', 9),\n",
      " ('행정각부', 9),\n",
      " ('선거관리', 9),\n",
      " ('생활', 9),\n",
      " ('기본', 9),\n",
      " ('명령', 9),\n",
      " ('통일', 9),\n",
      " ('절차', 9),\n",
      " ('국정', 9),\n",
      " ('제정', 8)]\n"
     ]
    }
   ],
   "source": [
    "# POS tag a sentence\n",
    "s = kolaw.open('constitution.txt').read() # 한국 법률 말뭉치\n",
    "words = okt.pos(s)\n",
    "\n",
    "# Define a chunk grammar, or chunking rules, then chunk # Noun phrase\n",
    "grammar = 'NP: {<N.*>*<Suffix>?}'\n",
    "parser = nltk.RegexpParser(grammar)\n",
    "chunks = parser.parse(words)\n",
    "chunks = [ chunk.leaves() for chunk in chunks if type(chunk) != tuple ]\n",
    "\n",
    "# chunk를 본문과 같이 만들고 빈도 수 카운팅\n",
    "result = set()\n",
    "for chunk in chunks:\n",
    "    seq = [w for w, t in chunk]\n",
    "    pattern = '[ ]?'.join(seq)\n",
    "    if len(pattern) < 2:\n",
    "        continue\n",
    "    seq_pattern = re.compile(pattern)\n",
    "    founds = re.findall(seq_pattern, s)\n",
    "    len_founds = len(founds)\n",
    "    if not len_founds:\n",
    "        continue\n",
    "    ele = (founds[0], len_founds)\n",
    "    if len(set(founds)) > 1:\n",
    "        ele = (tuple(set(founds)), len_founds)\n",
    "    result.add(ele)\n",
    "\n",
    "result = sorted(list(result), key=lambda x:x[1], reverse=True)\n",
    "pprint(result[80:100]) # print chunks and counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f067b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd_env",
   "language": "python",
   "name": "sd_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
